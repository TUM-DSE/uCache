# uCache

This repository contains the artifacts of the FAST'26 paper: "uCache: A Customizable Unikernel-based IO Cache".

## Overview

### Repository structure
The project is structured as follows:

```
.
├── benchmark: Contains the benchmarks scripts
├──── results: (not gitted) contains the csv files generated by the benchmark scripts
├──── plots: contains the python scripts to generate the plots
├── nix: Contains Nix definition for the VMs and for competitors
├── osv: Contains the uCache prototype (in the ucache branch)
├──── include/osv/ ucache.hh,ufs.hh: headers for uCache and the uVFS.
├──── core/ ucache.cc,ufs.cc: code for uCache and the uVFS.
├──── benchmarks: contains the benchmarks code for OSv.
├──── core/llfree/: our port of LLFree to OSv.
├──── modules/ libext/lwext: source code for the ext4 implementation of OSv.
└── VMs: (not gitted) Contains the VM images created for the experiments
```

Our evaluation setup uses [just]() and [Nix]() to facilitate reproduction. For each command, we give the command to run and explain what it is doing in the background.

### Benchmarks

Our evaluation revolves around 4 experiments:
- mmapbench (in [Linux](https://github.com/Meandres/mmapbench) and [OSv](https://github.com/Meandres/osv_benchmarks/tree/master/mmapbench))
- IO benchmark (fio in [Linux](https://github.com/axboe/fio) and our custom benchmark on [OSv](https://github.com/Meandres/osv_benchmarks/tree/master/nvmebench))
- vmcache (in [Linux](https://github.com/viktorleis/vmcache) and [OSv](https://github.com/Meandres/osv_benchmarks/tree/master/integrated_vmcache))
- DuckDB (in [Linux](https://github.com/duckdb/duckdb/tree/v1.4.1) and [OSv](https://github.com/Meandres/osv_benchmarks/tree/master/duckdb))


## Setup the environment

To run the experiments, you should have a server with at least 64 cores and 256GiB of RAM. The disk footprint of experiments (VM images and results) is around 10GiB.

The server should also include a spare NVMe SSD (capacity >=1.5TiB) that can be overwritten. The experiments presented in the paper use a PCI 5.0 SSD, the [KIOXIA CM-7](https://europe.kioxia.com/en-europe/business/ssd/enterprise-ssd/cm7-r.html).

### Using your own machine

#### 1. Nix

If you choose to use your own machine and have a working Nix installation, please skip this step.

If you do not have Nix installed, you can either install it using the instructions [here](https://nixos.org/download/), or use our provided Docker image that sets up a working Nix environment with `just -f benchmarks/init.just enter_docker`  
TODO: make the docker image work

#### 2. System configuration

TODO: add settings:
- performance governor
- any other parameters ?


#### 3. Benchmarks configuration

Instruct them to look at the parameters at the top of the justfiles
- number of repetitions
- PCI ID of the SSD
- other benchmark specific parameters.


### Using our cluster's machine

In case you do not have a machine that can reproduce all experiments, we can provide access to a machine in our cluster (hostname: `irene`).

**IMPORTANT**: The `/home/` directory is synchronized across our cluster using NFS. Please use the `/scratch/{your_username}/` folder instead.


## Setup the benchmarks

1. To build the VM images, you can execute: `just -f benchmarks/init.just build_images`.  
_Explanation_:
```
This recipe internally calls linux-image-init and osv-image-init. We reuse the Linux VM image for all baseline and build one OSv image for each benchmark.  
The Linux image is built using the nix/image.nix definition.

Expected time: ~5 mins.
```

2. To initialize the filesystem in the SSD, execute `just reset_fs`  
_Explanation_:
```
This recipe switches to the NVMe driver and creates an ext4 filesystem.
After mounting the FS on a temporary location, it creates a file /cache and writes zeroes to it (~1300GiB).
Afterwards it re-binds the SSD to the vfio driver.

Expected time: ~5 mins with a PCI 5.0 SSD.
```

3. To ensure that the VMs (and the VMM) are working as intended, execute `just -f benchmarks/init.just check_vms`  
_Explanation_:
```
This recipe boots a Linux VM and runs a simple command using ssh.
Then it executes the native-example OSv VM.

Expected time: ~1 min.
```
Note: we use the recipe `just ssh "poweroff"` to stop the Linux VM which leads in some cases to the following error: `error: Recipe 'ssh' failed on line 19 with exit code 255`. This is not a malfunctionning of the scripts.

## Run the benchmarks

### 1. Microbenchmarks

Execute using `just -f benchmarks/microbench.just run`  
_Explanation_:
```
This executes the mmapbench benchmark with varying number of threads and varying memory quota.
For uCache, it also executes with multiple page sizes.
The data generated by this experiment is used for figures 6 and 8.
Expected time: ~3 hours.
```

### 2. IO performance

Execute using `just -f benchmarks/fio.just run`  
_Explanation_:
```
This executes the fio/spdk_nvme_perf benchmark on Linux and our custom benchmark on OSv.
The data generated by this experiment is used for figure 7.
Expected time: ~45 mins.
```

### 3. vmcache

Execute using `just -f benchmarks/vmcache.just run`  
_Explanation_:
```
This execute the TPC-C workload on vmcache using the POSIX backend (pread/madvise)n, the exmap backend, and uCache.
The data generated by this experiment is used for figure 9.
Expected time: ~1 hours.
```

### 4. DuckDB

Execute using `just -f benchmarks/duckdb.just run`  
_Explanation_:
```
This executes all queries from the TPC-H benchmark except 15 using the default DuckDB and our port of DuckDB to uCache.
The data generated by this experiment is used for figure 10.
Expected time: ~1 hours.
```

## Plots

To generate the plots, execute `just -f benchmarks/plots.just draw`

_Explanation_:
```
This executes all plotting python scripts contained in the "benchmarks/plots" directory. Those scripts output pdf files in the "benchmarks/results" directory.
```
